{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Capstone Project\n\n### Objective\nNow that you have been equipped with the skills to use different Machine Learning algorithms, over the course of five weeks, you will have the opportunity to practice and apply it on a dataset. In this project, you will complete a notebook where you will build a classifier to predict whether a loan case will be paid off or not.\n\nYou load a historical dataset from previous loan applications, clean the data, and apply different classification algorithm on the data. You are expected to use the following algorithms to build your models:\n\nk-Nearest Neighbour\nDecision Tree\nSupport Vector Machine\nLogistic Regression\n\nThe results is reported as the accuracy of each classifier, using the following metrics when these are applicable:\nJaccard index\nF1-score\nLogLoss\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Data pre-processing"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Importing all necessary packages\n\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline\n\n#Install Seaborn for data visualization\n!conda install -c anaconda seaborn -y\nimport seaborn as sns"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Getting the dataset\n!wget -O loan_train.csv https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/FinalModule_Coursera/data/loan_train.csv"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Put the dataset into a nice Panda frame\ndf = pd.read_csv('loan_train.csv')\ndf.head()\ndf.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Convert any dates into proper dates\ndf['due_date'] = pd.to_datetime(df['due_date'])\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Understand the counts of the loan statuses\ndf['loan_status'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Visualize dataset with Seaborn (gender, principal, loan status)\nbins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Visualize dataset with Seaborn (gender, age, loan status)\nbins = np.linspace(df.age.min(), df.age.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'age', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#create a day of the week\ndf['dayofweek'] = df['effective_date'].dt.dayofweek\n\n#Visualize dataset with Seaborn (gender, day of week, loan status)\nbins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()\n\n#create a weekend binary variable if day of the week is > 4 (0- Mon, 1- Tues, 2- Wed, 3- Thu, 4-Fri, 5- Sat, 6-Sun)\ndf['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>4)  else 0)\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Converting categorical to binary variables "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#converting sex categorical variable into 0 for for male and 1 for female\ndf['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n\n#converting the loan categorical variable into 0 for PAIDOFF and 1 for COLLECTION\ndf['loan_status'].replace(to_replace=['PAIDOFF','COLLECTION'], value=[0,1],inplace=True)\n\n#using inplace to ensure the dataframe is overwritten with this new binary classification\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.groupby(['education'])['loan_status'].value_counts(normalize=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Assign all features we want to a new dataframe\nFeature = df[['Principal','terms','age','Gender','weekend']]\n\n#use one hot encoding technique to conver categorical varables to binary variables and append them to the feature dataframe\nFeature = df[['Principal','terms','age','Gender','weekend']]\nFeature.head()\nFeature.shape\n\nEducationDummies = pd.get_dummies(df[['education']])\nEducationDummies.shape\n\nFeature = pd.concat([Feature,EducationDummies], axis=1)\n#Feature.drop(['Master or Above'], axis = 1,inplace=True)\nFeature.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Converting the feature set into normalized values"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Putting everything in a new dataframe, because a lot of data manipulation will happen\nX = Feature\ny = df['loan_status'].values\n\n#Ensuring they are still compatibly shaped\nX.shape\ny.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Normalizing the features using scikit-learn\nX = preprocessing.StandardScaler().fit(X).transform(X)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Classification\n\nThe actual classification algorithms start from here.\n\n    K Nearest Neighbor(KNN)\n    Decision Tree\n    Support Vector Machine\n    Logistic Regression\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## K-Nearest Neighbour (KNN)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#import additional required libraries\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#splitting my dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42) #42 being the answer to life, the universe and everything\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}